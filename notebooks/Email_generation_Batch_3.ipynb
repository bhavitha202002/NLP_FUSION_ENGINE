{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te8G64iabqYr",
        "outputId": "e61a4d0f-d560-499f-a00a-9ccfc1ba46b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject : GENERATED EMAIL : \n",
            "\n",
            "hi [name]\n",
            "i am so happy that you asked me for a gift. i received the package from my secret ssn last week and it is wonderful! thankyou very much!! there will be no more gifts this year without your lovely note!!! as we get closer together in life please write back with lots of kisses...it means alot when two people are truly into each other.. love mark\n",
            "sincerely\n",
            "[name]\n",
            "\n",
            "---\n",
            "\n",
            "Subject : GENERATED EMAIL : \n",
            "\n",
            "hi [name]\n",
            "i am so glad that you asked me back. i enjoyed my time with yao last summer and it was fun spending the entire weekend at your house - we went out on saturday night after work (you were there from houston) for a little drink in honor of our engagement day! hope all is well now as far an experience going forward...and if things are up this week let's try not get discouraged!! love mark\n",
            "sincerely\n",
            "[name]\n",
            "\n",
            "---\n",
            "\n",
            "Subject : GENERATED EMAIL : \n",
            "\n",
            "hi [name]\n",
            ": i'm back in the office. my parents are coming for a few days next week and wanted me (and you) as they were going through some estate stuff with their grandchildren that we'll be talking about when our kids come over here sometime soon - it's been awhile since either of us spent any time there so this was somewhat nerve wracking but hopefully fun! hope all is well on your end...i know how incredibly busy life can get these last couple weeks especially after having such an incredible vacation at yosemite!! love-sally\n",
            "sincerely\n",
            "[name]\n",
            "\n",
            "---\n",
            "\n",
            "Subject : GENERATED EMAIL : \n",
            "\n",
            "hi [name]\n",
            " i'm back in the office and loving every minute of it! how are things? you're always right about sea kayaking or surfing (or both)?! hope all is well with your family - they were lovely while we was there last time...i'll talk later tony\n",
            "sincerely\n",
            "[name]\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import random\n",
        "import torch\n",
        "import traceback\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoConfig, AutoModelForPreTraining\n",
        "\n",
        "# Configurations\n",
        "SEED = 2020  # random seed value\n",
        "MODEL = \"sagorsarker/emailgenerator\"  # hf model name\n",
        "MAXLEN = 768\n",
        "# CUSTOM_MODEL_PATH = \"./model/pytorch_model.bin\"\n",
        "SPECIAL_TOKENS  = { \"bos_token\": \"<|BOS|>\",\n",
        "                    \"eos_token\": \"<|EOS|>\",\n",
        "                    \"unk_token\": \"<|UNK|>\",\n",
        "                    \"pad_token\": \"<|PAD|>\",\n",
        "                    \"sep_token\": \"<|SEP|>\"}\n",
        "\n",
        "GREET_TOKENS = [\"hi\", \"hey\", \"hello\", \"dear\"]\n",
        "START_GREET = \"hi [name]\\n\"\n",
        "CONCLUSION_GREET = \"\\nsincerely\\n[name]\"\n",
        "\n",
        "# Utils - seed initialization\n",
        "def seed_everything(seed):\n",
        "    \"\"\"initialize random seed\n",
        "\n",
        "    Args:\n",
        "        seed (int): random seed value\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "def get_tokenizer(special_tokens=None):\n",
        "    \"\"\"Get tokenizer\n",
        "\n",
        "    Args:\n",
        "        special_tokens (dict, optional): special token dictionary. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        obj: tokenizer object\n",
        "    \"\"\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "\n",
        "    if special_tokens:\n",
        "        tokenizer.add_special_tokens(special_tokens)\n",
        "    return tokenizer\n",
        "\n",
        "def get_model(tokenizer, special_tokens=None, load_model_path=None):\n",
        "    \"\"\"Get model from pretrained model\n",
        "\n",
        "    Args:\n",
        "        tokenizer (obj): tokenizer object\n",
        "        special_tokens (dict, optional): special token dictionary. Defaults to None.\n",
        "        load_model_path (str, optional): load model path. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        obj: model object\n",
        "    \"\"\"\n",
        "    config = AutoConfig.from_pretrained(\n",
        "            MODEL,\n",
        "            output_hidden_states=False\n",
        "        )\n",
        "    model = AutoModelForPreTraining.from_pretrained(MODEL, config=config)\n",
        "    if special_tokens:\n",
        "        model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "    if load_model_path:\n",
        "        model.load_state_dict(torch.load(load_model_path))\n",
        "\n",
        "    model.cuda()\n",
        "    return model\n",
        "\n",
        "def remove_special_token(text):\n",
        "    \"\"\"Remove special token from text\n",
        "\n",
        "    Args:\n",
        "        text (str): text to be processed\n",
        "\n",
        "    Returns:\n",
        "        _str: processed text\n",
        "    \"\"\"\n",
        "    for key, token in SPECIAL_TOKENS.items():\n",
        "        text = text.replace(token, '')\n",
        "    return text\n",
        "\n",
        "def start_with_greet(text, greet):\n",
        "    \"\"\"Check if text starts with greet\n",
        "\n",
        "    Args:\n",
        "        text (str): text to be checked\n",
        "        greet (list): list of greet tokens\n",
        "\n",
        "    Returns:\n",
        "        (bool, str): (True, greet token) if text starts with greet,\n",
        "                    (False, None) otherwise\n",
        "    \"\"\"\n",
        "    for g in greet:\n",
        "        if text.startswith(g):\n",
        "            return True, g\n",
        "    return False, None\n",
        "\n",
        "def post_processing(text, prompt):\n",
        "    \"\"\"Post processing generated email\n",
        "\n",
        "    Args:\n",
        "        text (str): text to be processed\n",
        "        prompt (str): prompt to be replaced\n",
        "\n",
        "    Returns:\n",
        "        str: processed text\n",
        "    \"\"\"\n",
        "    # remove prompt first\n",
        "    text = text.replace(prompt, '')\n",
        "    text = text.strip()\n",
        "    gexist, greet = start_with_greet(text, GREET_TOKENS)\n",
        "    if gexist:\n",
        "        regex = f\"^{greet}\\s?(\\w+)?[\\.,\\s]?\"\n",
        "        start_greet = greet + \" [name]\\n\"\n",
        "        text = re.sub(regex, start_greet, text)\n",
        "        text = text + CONCLUSION_GREET\n",
        "    else:\n",
        "        text = START_GREET + text + CONCLUSION_GREET\n",
        "    return text\n",
        "\n",
        "\n",
        "def join_keywords(keywords, randomize=True):\n",
        "    \"\"\"Join keywords with separator\n",
        "\n",
        "    Args:\n",
        "        keywords (list): list of bullets keywords\n",
        "        randomize (bool, optional): randomly take keyword. Defaults to True.\n",
        "\n",
        "    Returns:\n",
        "        str: joined keywords\n",
        "    \"\"\"\n",
        "    N = len(keywords)\n",
        "    if randomize:\n",
        "        M = random.choice(range(N + 1))\n",
        "        keywords = keywords[:M]\n",
        "        random.shuffle(keywords)\n",
        "\n",
        "    return ','.join(keywords)\n",
        "\n",
        "\n",
        "def generate_email(input_text: str, token_count: int,\n",
        "                   temperature: float, n_gen: int,\n",
        "                   keywords=None) -> dict:\n",
        "    \"\"\"Generate email from input text, keywords and trained model\n",
        "\n",
        "    Args:\n",
        "        input_text (str): input text\n",
        "        token_count (int): number of tokens to be generated\n",
        "        temperature (float): temperature for sampling\n",
        "        n_gen (int): number of generated emails\n",
        "        keywords (list, optional): list of keywords. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        dict: generated emails\n",
        "        {\n",
        "            \"status\": \"success\",\n",
        "            \"ai_results\": []\n",
        "        }\n",
        "    \"\"\"\n",
        "    output = {}\n",
        "    try:\n",
        "        tokenizer = get_tokenizer()\n",
        "        tokenizer.add_special_tokens(SPECIAL_TOKENS)\n",
        "        model = get_model(tokenizer,special_tokens = SPECIAL_TOKENS)\n",
        "        if keywords:\n",
        "            kw = join_keywords(keywords, randomize=False)\n",
        "            prompt = SPECIAL_TOKENS['bos_token'] + input_text + \\\n",
        "                     SPECIAL_TOKENS['sep_token'] + kw + SPECIAL_TOKENS['sep_token']\n",
        "        else:\n",
        "            prompt = SPECIAL_TOKENS['bos_token'] + input_text + \\\n",
        "                     SPECIAL_TOKENS['sep_token'] + SPECIAL_TOKENS['sep_token']\n",
        "\n",
        "        generated = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "        device = torch.device(\"cuda\")\n",
        "        generated = generated.to(device)\n",
        "\n",
        "        model.eval()\n",
        "        sample_outputs = model.generate(generated,\n",
        "                                        do_sample=True,\n",
        "                                        min_length=50,\n",
        "                                        max_length=MAXLEN,\n",
        "                                        top_k=30,\n",
        "                                        top_p=0.7,\n",
        "                                        temperature=temperature,\n",
        "                                        repetition_penalty=2.0,\n",
        "                                        num_return_sequences=n_gen\n",
        "                                        )\n",
        "        output['status'] = 'success'\n",
        "        output['ai_results'] = []\n",
        "        prompt = remove_special_token(prompt)\n",
        "        for i, sample_output in enumerate(sample_outputs):\n",
        "            text = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
        "            text = post_processing(text, prompt)\n",
        "            output['ai_results'].append({'generated_text': text, \"text_length\": len(text)})\n",
        "        output['ai_results'].reverse()\n",
        "    except Exception as e:\n",
        "        traceback.print_exc()\n",
        "        output['status'] = 'error'\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def test():\n",
        "    data = {\n",
        "        \"prompt\": \"love to visit again\",  # subject of the email\n",
        "        \"token_count\": 128,\n",
        "        \"temperature\": 0.6,\n",
        "        \"n_gen\": 4,\n",
        "        \"keywords\": ['experience', 'joyfull', 'sea']\n",
        "    }\n",
        "\n",
        "    response = generate_email(data['prompt'], data['token_count'], data['temperature'], data['n_gen'], data['keywords'])\n",
        "    for result_item in response['ai_results']:\n",
        "      print(\"Subject : GENERATED EMAIL : \\n\")\n",
        "      print(result_item['generated_text'])\n",
        "      print(\"\\n---\\n\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    test()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRXqljSwb2c0",
        "outputId": "50e37b45-7e8b-4bd3-f900-e20d2713fc00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject : GENERATED EMAIL : \n",
            "\n",
            "hi [name]\n",
            "i have been asked to request that i take 12 weeks of vacation from the 1st - 31 december 2001. if you need any further information please call me at 713-853 3488 or e:mail, jason wolfe thankyou\n",
            "sincerely\n",
            "[name]\n",
            "\n",
            "---\n",
            "\n",
            "Subject : GENERATED EMAIL : \n",
            "\n",
            "hi [name]\n",
            "i have a request to take off from work on friday, december 18th. i will be out of the office that day and need your assistance in getting me covered by my insurance while you are gone! please call or email with any questions at x30596 if this is something we can help answer together so it may get processed sooner!! thankyou very much!!!\n",
            "sincerely\n",
            "[name]\n",
            "\n",
            "---\n",
            "\n",
            "Subject : GENERATED EMAIL : \n",
            "\n",
            "hi [name]\n",
            "i am requesting a 10 day of vacation on friday, october 22nd. i have been ill since last wednesday and would like to take this time off as well so that my family can enjoy the holidays in peace (and hopefully without all those nasty doctors). please let me know if you are interested or not! thanks - eric x3-0977\n",
            "sincerely\n",
            "[name]\n",
            "\n",
            "---\n",
            "\n",
            "Subject : GENERATED EMAIL : \n",
            "\n",
            "hi [name]\n",
            "i have been asked to request a 12 day of vacation with pay. i will be out friday, october 25th and monday the 28-29st as well if that is ok w you please let me know what your availability looks like on those days so we can work it around in scheduling or compensation terms (ie) tuesday night afternoons off wednesday afternoon sunday morning etc...\n",
            "sincerely\n",
            "[name]\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def test():\n",
        "    data = {\n",
        "        \"prompt\": \"Requesting for sick leave\",  # subject of the email\n",
        "        \"token_count\": 128,\n",
        "        \"temperature\": 0.6,\n",
        "        \"n_gen\": 4,\n",
        "        #\"keywords\": ['experience', 'joyfull', 'sea']\n",
        "    }\n",
        "\n",
        "    response = generate_email(data['prompt'], data['token_count'], data['temperature'], data['n_gen'])\n",
        "                              #, data['keywords'])\n",
        "    for result_item in response['ai_results']:\n",
        "      print(\"Subject : GENERATED EMAIL : \\n\")\n",
        "      print(result_item['generated_text'])\n",
        "      print(\"\\n---\\n\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBhcBh25eqCF"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "save_dir = '/content/drive/My Drive/Email_Generation'\n",
        "\n",
        "# Save the model to the specified directory\n",
        "model.save(save_dir)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
