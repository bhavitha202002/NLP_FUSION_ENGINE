{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ9nZ6xYBWko"
      },
      "source": [
        "# English-to-Spanish translation with a sequence-to-sequence Transformer\n",
        "\n",
        "\n",
        "**Description:** Implementing a sequence-to-sequence Transformer and training it on a machine translation task.<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qUMDGUGBWk0"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this example, we'll build a sequence-to-sequence Transformer model, which\n",
        "we'll train on an English-to-Spanish machine translation task.\n",
        "\n",
        "You'll learn how to:\n",
        "\n",
        "- Vectorize text using the Keras `TextVectorization` layer.\n",
        "- Implement a `TransformerEncoder` layer, a `TransformerDecoder` layer,\n",
        "and a `PositionalEmbedding` layer.\n",
        "- Prepare data for training a sequence-to-sequence model.\n",
        "- Use the trained model to generate translations of never-seen-before\n",
        "input sentences (sequence-to-sequence inference).\n",
        "\n",
        "The code featured here is adapted from the book\n",
        "[Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition)\n",
        "(chapter 11: Deep learning for text).\n",
        "The present example is fairly barebones, so for detailed explanations of\n",
        "how each building block works, as well as the theory behind Transformers,\n",
        "I recommend reading the book."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wbH9lzFBWk2"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "TtbfwN8MBm8Y",
        "outputId": "1ee922e9-68d6-4009-f441-438857e8386d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras==3.0.0\n",
            "  Using cached keras-3.0.0-py3-none-any.whl (997 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras==3.0.0) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras==3.0.0) (1.23.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras==3.0.0) (13.7.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras==3.0.0) (0.0.7)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras==3.0.0) (3.9.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras==3.0.0) (0.1.8)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras==3.0.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras==3.0.0) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras==3.0.0) (0.1.2)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0.post1 requires keras<2.16,>=2.15.0, but you have keras 3.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-3.0.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install keras==3.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vvb0rwcbB90m",
        "outputId": "9704c554-4afa-41e1-a382-c9f523d3d823"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0.post1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /root/.local/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.9.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow)\n",
            "  Using cached keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /root/.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.0.0\n",
            "    Uninstalling keras-3.0.0:\n",
            "      Successfully uninstalled keras-3.0.0\n",
            "Successfully installed keras-2.15.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "x4TlvgFvBWk4"
      },
      "outputs": [],
      "source": [
        "# We set the backend to TensorFlow. The code works with\n",
        "# both `tensorflow` and `torch`. It does not work with JAX\n",
        "# due to the behavior of `jax.numpy.tile` in a jit scope\n",
        "# (used in `TransformerDecoder.get_causal_attention_mask()`:\n",
        "# `tile` in JAX does not support a dynamic `reps` argument.\n",
        "# You can make the code work in JAX by wrapping the\n",
        "# inside of the `get_causal_attention_mask` method in\n",
        "# a decorator to prevent jit compilation:\n",
        "# `with jax.ensure_compile_time_eval():`.\n",
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow.data as tf_data\n",
        "import tensorflow.strings as tf_strings\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import ops\n",
        "from keras.layers import TextVectorization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8r8aJFRBWk6"
      },
      "source": [
        "## Downloading the data\n",
        "\n",
        "We'll be working with an English-to-Spanish translation dataset\n",
        "provided by [Anki](https://www.manythings.org/anki/). Let's download it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "-BAmtwlXBWk7"
      },
      "outputs": [],
      "source": [
        "text_file = keras.utils.get_file(\n",
        "    fname=\"spa-eng.zip\",\n",
        "    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n",
        "    extract=True,\n",
        ")\n",
        "text_file = pathlib.Path(text_file).parent / \"spa-eng\" / \"spa.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoKy5B28BWk8"
      },
      "source": [
        "## Parsing the data\n",
        "\n",
        "Each line contains an English sentence and its corresponding Spanish sentence.\n",
        "The English sentence is the *source sequence* and Spanish one is the *target sequence*.\n",
        "We prepend the token `\"[start]\"` and we append the token `\"[end]\"` to the Spanish sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "aCbdl5jMBWk9"
      },
      "outputs": [],
      "source": [
        "with open(text_file) as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "text_pairs = []\n",
        "for line in lines:\n",
        "    eng, spa = line.split(\"\\t\")\n",
        "    spa = \"[start] \" + spa + \" [end]\"\n",
        "    text_pairs.append((eng, spa))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3PskKQLBWk_"
      },
      "source": [
        "Here's what our sentence pairs look like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHDZlWF-BWk_",
        "outputId": "20319d31-2667-4529-9d31-3a8b50c0c6dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('This is almost as good as fishing.', '[start] Esto es casi tan bueno como pescar. [end]')\n",
            "(\"Tom seems awfully sad, doesn't he?\", '[start] Tom parece tristísimo, ¿no? [end]')\n",
            "('She advised him to walk instead of taking a bus.', '[start] Le aconsejó que caminara en vez de tomar una micro. [end]')\n",
            "('These people were very lucky.', '[start] Estas personas fueron muy afortunadas. [end]')\n",
            "('He bought flour and oil in quantity.', '[start] Él compró un montón de harina y de aceite. [end]')\n"
          ]
        }
      ],
      "source": [
        "for _ in range(5):\n",
        "    print(random.choice(text_pairs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu1R4h-EBWlA"
      },
      "source": [
        "Now, let's split the sentence pairs into a training set, a validation set,\n",
        "and a test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzPCZDnBBWlA",
        "outputId": "03034a61-95cb-411d-83c4-f2436f20e923"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "118964 total pairs\n",
            "83276 training pairs\n",
            "17844 validation pairs\n",
            "17844 test pairs\n"
          ]
        }
      ],
      "source": [
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
        "\n",
        "print(f\"{len(text_pairs)} total pairs\")\n",
        "print(f\"{len(train_pairs)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")\n",
        "print(f\"{len(test_pairs)} test pairs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFWVJpbTBWlA"
      },
      "source": [
        "## Vectorizing the text data\n",
        "\n",
        "We'll use two instances of the `TextVectorization` layer to vectorize the text\n",
        "data (one for English and one for Spanish),\n",
        "that is to say, to turn the original strings into integer sequences\n",
        "where each integer represents the index of a word in a vocabulary.\n",
        "\n",
        "The English layer will use the default string standardization (strip punctuation characters)\n",
        "and splitting scheme (split on whitespace), while\n",
        "the Spanish layer will use a custom standardization, where we add the character\n",
        "`\"¿\"` to the set of punctuation characters to be stripped.\n",
        "\n",
        "Note: in a production-grade machine translation model, I would not recommend\n",
        "stripping the punctuation characters in either language. Instead, I would recommend turning\n",
        "each punctuation character into its own token,\n",
        "which you could achieve by providing a custom `split` function to the `TextVectorization` layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "r8SRFSn6BWlB"
      },
      "outputs": [],
      "source": [
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf_strings.lower(input_string)\n",
        "    return tf_strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
        "\n",
        "\n",
        "eng_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "spa_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "train_eng_texts = [pair[0] for pair in train_pairs]\n",
        "train_spa_texts = [pair[1] for pair in train_pairs]\n",
        "eng_vectorization.adapt(train_eng_texts)\n",
        "spa_vectorization.adapt(train_spa_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U-rk6pWBWlB"
      },
      "source": [
        "Next, we'll format our datasets.\n",
        "\n",
        "At each training step, the model will seek to predict target words N+1 (and beyond)\n",
        "using the source sentence and the target words 0 to N.\n",
        "\n",
        "As such, the training dataset will yield a tuple `(inputs, targets)`, where:\n",
        "\n",
        "- `inputs` is a dictionary with the keys `encoder_inputs` and `decoder_inputs`.\n",
        "`encoder_inputs` is the vectorized source sentence and `encoder_inputs` is the target sentence \"so far\",\n",
        "that is to say, the words 0 to N used to predict word N+1 (and beyond) in the target sentence.\n",
        "- `target` is the target sentence offset by one step:\n",
        "it provides the next words in the target sentence -- what the model will try to predict."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "-2Ka_FpHBWlC"
      },
      "outputs": [],
      "source": [
        "\n",
        "def format_dataset(eng, spa):\n",
        "    eng = eng_vectorization(eng)\n",
        "    spa = spa_vectorization(spa)\n",
        "    return (\n",
        "        {\n",
        "            \"encoder_inputs\": eng,\n",
        "            \"decoder_inputs\": spa[:, :-1],\n",
        "        },\n",
        "        spa[:, 1:],\n",
        "    )\n",
        "\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, spa_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    spa_texts = list(spa_texts)\n",
        "    dataset = tf_data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.cache().shuffle(2048).prefetch(16)\n",
        "\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRyU_nFuBWlC"
      },
      "source": [
        "Let's take a quick look at the sequence shapes\n",
        "(we have batches of 64 pairs, and all sequences are 20 steps long):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9Ozk0dABWlC",
        "outputId": "61ce103c-3eff-43b9-d469-75c5e51b11c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (64, 20)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqMvzVwOBWlC"
      },
      "source": [
        "## Building the model\n",
        "\n",
        "Our sequence-to-sequence Transformer consists of a `TransformerEncoder`\n",
        "and a `TransformerDecoder` chained together. To make the model aware of word order,\n",
        "we also use a `PositionalEmbedding` layer.\n",
        "\n",
        "The source sequence will be pass to the `TransformerEncoder`,\n",
        "which will produce a new representation of it.\n",
        "This new representation will then be passed\n",
        "to the `TransformerDecoder`, together with the target sequence so far (target words 0 to N).\n",
        "The `TransformerDecoder` will then seek to predict the next words in the target sequence (N+1 and beyond).\n",
        "\n",
        "A key detail that makes this possible is causal masking\n",
        "(see method `get_causal_attention_mask()` on the `TransformerDecoder`).\n",
        "The `TransformerDecoder` sees the entire sequences at once, and thus we must make\n",
        "sure that it only uses information from target tokens 0 to N when predicting token N+1\n",
        "(otherwise, it could use information from the future, which would\n",
        "result in a model that cannot be used at inference time)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "RSolHWyCBWlC"
      },
      "outputs": [],
      "source": [
        "import keras.ops as ops\n",
        "\n",
        "\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(dense_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\")\n",
        "        else:\n",
        "            padding_mask = None\n",
        "\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "                \"dense_dim\": self.dense_dim,\n",
        "                \"num_heads\": self.num_heads,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = ops.shape(inputs)[-1]\n",
        "        positions = ops.arange(0, length, 1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        if mask is None:\n",
        "            return None\n",
        "        else:\n",
        "            return ops.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"sequence_length\": self.sequence_length,\n",
        "                \"vocab_size\": self.vocab_size,\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(latent_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\")\n",
        "            padding_mask = ops.minimum(padding_mask, causal_mask)\n",
        "        else:\n",
        "            padding_mask = None\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = ops.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = ops.arange(sequence_length)[:, None]\n",
        "        j = ops.arange(sequence_length)\n",
        "        mask = ops.cast(i >= j, dtype=\"int32\")\n",
        "        mask = ops.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = ops.concatenate(\n",
        "            [ops.expand_dims(batch_size, -1), ops.convert_to_tensor([1, 1])],\n",
        "            axis=0,\n",
        "        )\n",
        "        return ops.tile(mask, mult)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "                \"latent_dim\": self.latent_dim,\n",
        "                \"num_heads\": self.num_heads,\n",
        "            }\n",
        "        )\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7icFjBiBWlD"
      },
      "source": [
        "Next, we assemble the end-to-end model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "w-hzOTznBWlE"
      },
      "outputs": [],
      "source": [
        "embed_dim = 256\n",
        "latent_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "transformer = keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7H-9qazBWlE"
      },
      "source": [
        "## Training our model\n",
        "\n",
        "We'll use accuracy as a quick way to monitor training progress on the validation data.\n",
        "Note that machine translation typically uses BLEU scores as well as other metrics, rather than accuracy.\n",
        "\n",
        "Here we only train for 1 epoch, but to get the model to actually converge\n",
        "you should train for at least 30 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qzJht7tqBWlE",
        "outputId": "90f63d2d-fffc-44da-9a92-503d519b7932"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"transformer\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │            │                            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ positional_embedding_4    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,120</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)     │                        │            │                            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ decoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │            │                            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ transformer_encoder_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,155,456</span> │ positional_embedding_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)      │                        │            │                            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ functional_17             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)    │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12,959,640</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │                        │            │ transformer_encoder_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "└───────────────────────────┴────────────────────────┴────────────┴────────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │          \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │            │                            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ positional_embedding_4    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │  \u001b[38;5;34m3,845,120\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)     │                        │            │                            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ decoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │          \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │            │                            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ transformer_encoder_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │  \u001b[38;5;34m3,155,456\u001b[0m │ positional_embedding_4[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)      │                        │            │                            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ functional_17             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15000\u001b[0m)    │ \u001b[38;5;34m12,959,640\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)              │                        │            │ transformer_encoder_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "└───────────────────────────┴────────────────────────┴────────────┴────────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,216</span> (76.14 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,960,216\u001b[0m (76.14 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,216</span> (76.14 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,960,216\u001b[0m (76.14 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 58ms/step - accuracy: 0.7117 - loss: 2.2062 - val_accuracy: 0.8002 - val_loss: 1.2517\n",
            "Epoch 2/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 51ms/step - accuracy: 0.8144 - loss: 1.1822 - val_accuracy: 0.8539 - val_loss: 0.8881\n",
            "Epoch 3/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 51ms/step - accuracy: 0.8542 - loss: 0.8894 - val_accuracy: 0.8649 - val_loss: 0.7955\n",
            "Epoch 4/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 51ms/step - accuracy: 0.8695 - loss: 0.7715 - val_accuracy: 0.8712 - val_loss: 0.7591\n",
            "Epoch 5/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 52ms/step - accuracy: 0.8799 - loss: 0.6975 - val_accuracy: 0.8777 - val_loss: 0.7153\n",
            "Epoch 6/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 52ms/step - accuracy: 0.8867 - loss: 0.6476 - val_accuracy: 0.8817 - val_loss: 0.7059\n",
            "Epoch 7/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 51ms/step - accuracy: 0.8924 - loss: 0.6156 - val_accuracy: 0.8826 - val_loss: 0.6981\n",
            "Epoch 8/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 51ms/step - accuracy: 0.8975 - loss: 0.5816 - val_accuracy: 0.8839 - val_loss: 0.6914\n",
            "Epoch 9/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 51ms/step - accuracy: 0.9009 - loss: 0.5606 - val_accuracy: 0.8841 - val_loss: 0.6947\n",
            "Epoch 10/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 51ms/step - accuracy: 0.9041 - loss: 0.5413 - val_accuracy: 0.8851 - val_loss: 0.7002\n",
            "Epoch 11/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 51ms/step - accuracy: 0.9068 - loss: 0.5272 - val_accuracy: 0.8859 - val_loss: 0.7015\n",
            "Epoch 12/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 51ms/step - accuracy: 0.9099 - loss: 0.5111 - val_accuracy: 0.8868 - val_loss: 0.7097\n",
            "Epoch 13/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 50ms/step - accuracy: 0.9122 - loss: 0.4979 - val_accuracy: 0.8863 - val_loss: 0.7192\n",
            "Epoch 14/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 51ms/step - accuracy: 0.9138 - loss: 0.4878 - val_accuracy: 0.8839 - val_loss: 0.7299\n",
            "Epoch 15/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 52ms/step - accuracy: 0.9156 - loss: 0.4793 - val_accuracy: 0.8858 - val_loss: 0.7301\n",
            "Epoch 16/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 51ms/step - accuracy: 0.9175 - loss: 0.4700 - val_accuracy: 0.8855 - val_loss: 0.7412\n",
            "Epoch 17/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 50ms/step - accuracy: 0.9192 - loss: 0.4628 - val_accuracy: 0.8852 - val_loss: 0.7500\n",
            "Epoch 18/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 50ms/step - accuracy: 0.9212 - loss: 0.4519 - val_accuracy: 0.8854 - val_loss: 0.7633\n",
            "Epoch 19/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 50ms/step - accuracy: 0.9226 - loss: 0.4443 - val_accuracy: 0.8853 - val_loss: 0.7608\n",
            "Epoch 20/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 50ms/step - accuracy: 0.9239 - loss: 0.4362 - val_accuracy: 0.8857 - val_loss: 0.7736\n",
            "Epoch 21/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 51ms/step - accuracy: 0.9251 - loss: 0.4306 - val_accuracy: 0.8857 - val_loss: 0.7758\n",
            "Epoch 22/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 51ms/step - accuracy: 0.9262 - loss: 0.4281 - val_accuracy: 0.8862 - val_loss: 0.7747\n",
            "Epoch 23/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 51ms/step - accuracy: 0.9280 - loss: 0.4187 - val_accuracy: 0.8871 - val_loss: 0.7852\n",
            "Epoch 24/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 51ms/step - accuracy: 0.9292 - loss: 0.4122 - val_accuracy: 0.8869 - val_loss: 0.7885\n",
            "Epoch 25/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 51ms/step - accuracy: 0.9305 - loss: 0.4055 - val_accuracy: 0.8869 - val_loss: 0.8147\n",
            "Epoch 26/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 50ms/step - accuracy: 0.9318 - loss: 0.3984 - val_accuracy: 0.8864 - val_loss: 0.8180\n",
            "Epoch 27/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 50ms/step - accuracy: 0.9321 - loss: 0.3976 - val_accuracy: 0.8862 - val_loss: 0.8129\n",
            "Epoch 28/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 50ms/step - accuracy: 0.9331 - loss: 0.3911 - val_accuracy: 0.8866 - val_loss: 0.8360\n",
            "Epoch 29/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 49ms/step - accuracy: 0.9342 - loss: 0.3865 - val_accuracy: 0.8853 - val_loss: 0.8390\n",
            "Epoch 30/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 49ms/step - accuracy: 0.9348 - loss: 0.3835 - val_accuracy: 0.8848 - val_loss: 0.8411\n",
            "Epoch 31/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 50ms/step - accuracy: 0.9354 - loss: 0.3811 - val_accuracy: 0.8866 - val_loss: 0.8504\n",
            "Epoch 32/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 50ms/step - accuracy: 0.9359 - loss: 0.3787 - val_accuracy: 0.8866 - val_loss: 0.8569\n",
            "Epoch 33/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 50ms/step - accuracy: 0.9372 - loss: 0.3728 - val_accuracy: 0.8857 - val_loss: 0.8679\n",
            "Epoch 34/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 49ms/step - accuracy: 0.9372 - loss: 0.3748 - val_accuracy: 0.8843 - val_loss: 0.8847\n",
            "Epoch 35/35\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 51ms/step - accuracy: 0.9383 - loss: 0.3672 - val_accuracy: 0.8868 - val_loss: 0.8852\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f4ec9ecfb50>"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "epochs = 35  # This should be at least 30 for convergence\n",
        "\n",
        "transformer.summary()\n",
        "transformer.compile(\n",
        "    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3csMhbNbBWlE"
      },
      "source": [
        "## Decoding test sentences\n",
        "\n",
        "Finally, let's demonstrate how to translate brand new English sentences.\n",
        "We simply feed into the model the vectorized English sentence\n",
        "as well as the target token `\"[start]\"`, then we repeatedly generated the next token, until\n",
        "we hit the token `\"[end]\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6Qpq4IjBWlF",
        "outputId": "cda0f3c4-1af3-4286-a036-10ed41780a74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "** Example 0 **\n",
            "A bunch of people died in the explosion.\n",
            "[start] un montón de gente murió en la explosión [end]\n",
            "\n",
            "** Example 1 **\n",
            "Have you seen them?\n",
            "[start] los has visto [end]\n",
            "\n",
            "** Example 2 **\n",
            "Come and see me whenever it is convenient for you.\n",
            "[start] venga y yo haga cuenta que yo haga cuenta vos [end]\n",
            "\n",
            "** Example 3 **\n",
            "I don't understand the questions that the teacher asks.\n",
            "[start] no entiendo las preguntas que el profesor de la profesora [end]\n",
            "\n",
            "** Example 4 **\n",
            "Don't you ever speak to me like that again.\n",
            "[start] no me hables de nuevo esa vez [end]\n",
            "\n",
            "** Example 5 **\n",
            "I need an assistant.\n",
            "[start] necesito un asistente [end]\n",
            "\n",
            "** Example 6 **\n",
            "Let's make a cake.\n",
            "[start] hagámoslo una torta [end]\n",
            "\n",
            "** Example 7 **\n",
            "Do you let your children eat ice cream?\n",
            "[start] dejes que tus niños [UNK] usted come helado [end]\n",
            "\n",
            "** Example 8 **\n",
            "Tom still can't get Mary out of his head.\n",
            "[start] tom todavía no puede salir a mary de su cabeza [end]\n",
            "\n",
            "** Example 9 **\n",
            "Last year, I decided to come to Japan.\n",
            "[start] el año pasado decidí pasar de japón [end]\n",
            "\n",
            "** Example 10 **\n",
            "It wasn't me who slammed the door.\n",
            "[start] no me fue [UNK] quién [UNK] [end]\n",
            "\n",
            "** Example 11 **\n",
            "Moths are attracted by light.\n",
            "[start] las llega querés antes de luz [end]\n",
            "\n",
            "** Example 12 **\n",
            "She was born lucky.\n",
            "[start] ella nació de suerte [end]\n",
            "\n",
            "** Example 13 **\n",
            "Why is she hiding?\n",
            "[start] por qué ella está escondiendo [end]\n",
            "\n",
            "** Example 14 **\n",
            "The sum of 5 and 3 is 8.\n",
            "[start] la suma de 5 3 cuando las ocho [end]\n",
            "\n",
            "** Example 15 **\n",
            "I'd better be on my way.\n",
            "[start] yo estaría mejor en mi camino [end]\n",
            "\n",
            "** Example 16 **\n",
            "Choose any one from among these.\n",
            "[start] elige uno al desde estos [end]\n",
            "\n",
            "** Example 17 **\n",
            "Tom did not struggle.\n",
            "[start] tom no [UNK] [end]\n",
            "\n",
            "** Example 18 **\n",
            "We're lucky to be alive.\n",
            "[start] tenemos suerte de estar vivo [end]\n",
            "\n",
            "** Example 19 **\n",
            "You can't buy it anywhere but there.\n",
            "[start] no puedes hacerlo pero ninguna parte [end]\n",
            "\n",
            "** Example 20 **\n",
            "She went to Europe via America.\n",
            "[start] ella se fue a europa en europa [end]\n",
            "\n",
            "** Example 21 **\n",
            "Tom was loyal.\n",
            "[start] tom era [UNK] [end]\n",
            "\n",
            "** Example 22 **\n",
            "I'm the only person who knows where Tom is.\n",
            "[start] soy la única persona que conoce tom [end]\n",
            "\n",
            "** Example 23 **\n",
            "Have you washed the car yet?\n",
            "[start] ya has lavar el auto [end]\n",
            "\n",
            "** Example 24 **\n",
            "Tom is the tallest in his family.\n",
            "[start] tom es el más alto de su familia [end]\n",
            "\n",
            "** Example 25 **\n",
            "We can't sleep because of the noise.\n",
            "[start] no podemos dormir por el ruido [end]\n",
            "\n",
            "** Example 26 **\n",
            "Pigeons can find their way home with the help of the Earth's magnetic field.\n",
            "[start] las palomas en casa de ver con el campo de la caja de la [UNK] occidental [end]\n",
            "\n",
            "** Example 27 **\n",
            "You have to be aggressive to be a success.\n",
            "[start] tienes que ser [UNK] ser un éxito [end]\n",
            "\n",
            "** Example 28 **\n",
            "I rang the bell.\n",
            "[start] hice la campana [end]\n",
            "\n",
            "** Example 29 **\n",
            "He muttered a curse.\n",
            "[start] Él la libertad está [UNK] [end]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spa_vocab = spa_vectorization.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = spa_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "\n",
        "        # ops.argmax(predictions[0, i, :]) is not a concrete value for jax here\n",
        "        sampled_token_index = ops.convert_to_numpy(\n",
        "            ops.argmax(predictions[0, i, :])\n",
        "        ).item(0)\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(30):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    translated = decode_sequence(input_sentence)\n",
        "    print(f\"** Example {_} **\")\n",
        "    print(input_sentence)\n",
        "    print(translated)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEvSR0OZBWlF"
      },
      "source": [
        "After 30 epochs, we get results such as:\n",
        "\n",
        "> She handed him the money.\n",
        "> [start] ella le pasó el dinero [end]\n",
        "\n",
        "> Tom has never heard Mary sing.\n",
        "> [start] tom nunca ha oído cantar a mary [end]\n",
        "\n",
        "> Perhaps she will come tomorrow.\n",
        "> [start] tal vez ella vendrá mañana [end]\n",
        "\n",
        "> I love to write.\n",
        "> [start] me encanta escribir [end]\n",
        "\n",
        "> His French is improving little by little.\n",
        "> [start] su francés va a [UNK] sólo un poco [end]\n",
        "\n",
        "> My hotel told me to call you.\n",
        "> [start] mi hotel me dijo que te [UNK] [end]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnKicER1FMhw",
        "outputId": "9ed750ff-a4df-44e6-fcb6-e144ff9d4111"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_nlp in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: keras-core in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (0.1.7)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (23.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (2023.12.25)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (13.7.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (0.1.8)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (0.1.9)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (2.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras_nlp) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras_nlp) (4.66.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_nlp) (0.0.7)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_nlp) (3.9.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras_nlp) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras_nlp) (2.16.1)\n",
            "Requirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras_nlp) (0.16.1)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras_nlp) (2.15.0.post1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras_nlp) (0.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /root/.local/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (4.9.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (1.60.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (2.15.0)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub>=0.13.0->tensorflow-text->keras_nlp) (2.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_nlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_nlp) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_nlp) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_nlp) (2024.2.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /root/.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (3.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_nlp\n",
        "import keras_nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lNsH8_kFv-I",
        "outputId": "5bcd0e07-0128-44ba-f943-5cb5fc826538"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.23.5)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install rouge-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "9W7lLURGGk9M"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade rouge-score\n",
        "!pip install -q --upgrade keras-nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgnQI5OWIZZD",
        "outputId": "58d445f0-d454-44db-eb0d-c5f105533186"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.23.5)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install rouge-score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "kka2fBNfIaV8"
      },
      "outputs": [],
      "source": [
        "from rouge_score import rouge_scorer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLMa2hpmIgeW",
        "outputId": "7ab7e655-8be9-4ff1-8eea-52d2c46dc1e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROUGE-1 Scores:  Score(precision=0.8333333333333334, recall=0.7142857142857143, fmeasure=0.7692307692307692)\n",
            "ROUGE-2 Scores:  Score(precision=0.4, recall=0.3333333333333333, fmeasure=0.3636363636363636)\n"
          ]
        }
      ],
      "source": [
        "from rouge_score import rouge_scorer\n",
        "import keras_nlp\n",
        "\n",
        "rouge_1 = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
        "rouge_2 = rouge_scorer.RougeScorer(['rouge2'], use_stemmer=True)\n",
        "\n",
        "for test_pair in test_pairs[:30]:\n",
        "    input_sentence = test_pair[0]\n",
        "    reference_sentence = test_pair[1]\n",
        "\n",
        "    translated_sentence = decode_sequence([input_sentence])\n",
        "    translated_sentence = (\n",
        "        translated_sentence.replace(\"[PAD]\", \"\")\n",
        "        .replace(\"[START]\", \"\")\n",
        "        .replace(\"[END]\", \"\")\n",
        "        .strip()\n",
        "    )\n",
        "\n",
        "    scores_1 = rouge_1.score(reference_sentence, translated_sentence)\n",
        "    scores_2 = rouge_2.score(reference_sentence, translated_sentence)\n",
        "\n",
        "print(\"ROUGE-1 Scores: \", scores_1['rouge1'])\n",
        "print(\"ROUGE-2 Scores: \", scores_2['rouge2'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_HyRY4zIwA4",
        "outputId": "ca85cdb7-61ba-436c-beab-903ff7bd5b0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| Input Sentence                                                          | Reference Sentence                                                               | Translated Sentence                                                           | ROUGE-1 Score                                                                               | ROUGE-2 Score                                                                                 |\n",
            "+=========================================================================+==================================================================================+===============================================================================+=============================================================================================+===============================================================================================+\n",
            "| Why did you decide to name your son Tom?                                | [start] ¿Por qué decidisteis ponerle Tom a vuestro hijo? [end]                   | [start] por qué te decidiste decir tu hijo tom [end]                          | Score(precision=0.6, recall=0.6, fmeasure=0.6)                                              | Score(precision=0.2222222222222222, recall=0.2222222222222222, fmeasure=0.2222222222222222)   |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| He looks young.                                                         | [start] Él se ve joven. [end]                                                    | [start] Él parece joven [end]                                                 | Score(precision=0.8, recall=0.6666666666666666, fmeasure=0.7272727272727272)                | Score(precision=0.5, recall=0.4, fmeasure=0.4444444444444445)                                 |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| Why do people kill themselves?                                          | [start] ¿Por qué la gente se suicida? [end]                                      | [start] por qué la gente sí mismos [end]                                      | Score(precision=0.75, recall=0.75, fmeasure=0.75)                                           | Score(precision=0.5714285714285714, recall=0.5714285714285714, fmeasure=0.5714285714285714)   |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| I want you to find Tom.                                                 | [start] Quiero que encuentres a Tom. [end]                                       | [start] quiero que encontraste a tom [end]                                    | Score(precision=0.8571428571428571, recall=0.8571428571428571, fmeasure=0.8571428571428571) | Score(precision=0.6666666666666666, recall=0.6666666666666666, fmeasure=0.6666666666666666)   |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| They went trudging across the desert.                                   | [start] Ellos cruzaron fatigosamente el desierto. [end]                          | [start] se [UNK] de la rueda al desierto [end]                                | Score(precision=0.3333333333333333, recall=0.42857142857142855, fmeasure=0.375)             | Score(precision=0.125, recall=0.16666666666666666, fmeasure=0.14285714285714288)              |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| I'm really not much of a guitarist.                                     | [start] No le pego mucho a la guitarra en realidad. [end]                        | [start] es que no soy muy guitarrista [end]                                   | Score(precision=0.375, recall=0.2727272727272727, fmeasure=0.3157894736842105)              | Score(precision=0.0, recall=0.0, fmeasure=0.0)                                                |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| The kids are asleep.                                                    | [start] Los niños están dormidos. [end]                                          | [start] los niños están durmiendo [end]                                       | Score(precision=0.875, recall=0.875, fmeasure=0.875)                                        | Score(precision=0.7142857142857143, recall=0.7142857142857143, fmeasure=0.7142857142857143)   |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| She rejected my proposal.                                               | [start] Ella rechazó mi propuesta. [end]                                         | [start] ella rechazó mi propuesta [end]                                       | Score(precision=1.0, recall=1.0, fmeasure=1.0)                                              | Score(precision=1.0, recall=1.0, fmeasure=1.0)                                                |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| The first step is the most difficult.                                   | [start] El primer paso es el más difícil. [end]                                  | [start] el primer paso es el difícil [end]                                    | Score(precision=1.0, recall=0.8181818181818182, fmeasure=0.9)                               | Score(precision=0.875, recall=0.7, fmeasure=0.7777777777777777)                               |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| I tried to call him up, but the line was busy.                          | [start] Traté de llamarlo, pero la línea estaba ocupada. [end]                   | [start] intenté hacerlo pero la línea [end]                                   | Score(precision=0.75, recall=0.5454545454545454, fmeasure=0.631578947368421)                | Score(precision=0.42857142857142855, recall=0.3, fmeasure=0.3529411764705882)                 |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| She frequently gets sugar and salt mixed up.                            | [start] Ella a menudo confunde el azúcar y la sal. [end]                         | [start] a menudo el azúcar y se [UNK] [end]                                   | Score(precision=0.8, recall=0.6666666666666666, fmeasure=0.7272727272727272)                | Score(precision=0.4444444444444444, recall=0.36363636363636365, fmeasure=0.39999999999999997) |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| I just want you to be involved.                                         | [start] Sólo pretendo que te impliques. [end]                                    | [start] sólo quiero que estés involucrado [end]                               | Score(precision=0.5555555555555556, recall=0.625, fmeasure=0.5882352941176471)              | Score(precision=0.25, recall=0.2857142857142857, fmeasure=0.26666666666666666)                |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| What time do you call your wife?                                        | [start] ¿A qué hora llamas a tu esposa? [end]                                    | [start] a qué hora llama a tu esposa [end]                                    | Score(precision=1.0, recall=1.0, fmeasure=1.0)                                              | Score(precision=1.0, recall=1.0, fmeasure=1.0)                                                |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| Let's watch TV here.                                                    | [start] Veamos la televisión aquí. [end]                                         | [start] veamos la televisión [end]                                            | Score(precision=1.0, recall=0.8571428571428571, fmeasure=0.923076923076923)                 | Score(precision=0.8, recall=0.6666666666666666, fmeasure=0.7272727272727272)                  |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| While they were away on holiday, their neighbours looked after the dog. | [start] Cuando ellos estaban de vacaciones, sus vecinos cuidaron al perro. [end] | [start] ellos estaban de aquí mientras [UNK] sus vecinos [UNK] al perro [end] | Score(precision=0.6923076923076923, recall=0.75, fmeasure=0.7199999999999999)               | Score(precision=0.4166666666666667, recall=0.45454545454545453, fmeasure=0.43478260869565216) |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| Do you know any Canadians living in Australia?                          | [start] ¿Conoces a algún canadiense que viva en Australia? [end]                 | [start] conoce a algún canadiense en australia [end]                          | Score(precision=1.0, recall=0.8181818181818182, fmeasure=0.9)                               | Score(precision=0.875, recall=0.7, fmeasure=0.7777777777777777)                               |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| I would rather stay at home than go shopping.                           | [start] Prefiero quedarme en casa a salir de compras. [end]                      | [start] preferiría quedarme de compras en casa que ir de compras [end]        | Score(precision=0.6153846153846154, recall=0.8, fmeasure=0.6956521739130435)                | Score(precision=0.25, recall=0.3333333333333333, fmeasure=0.28571428571428575)                |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| They work together.                                                     | [start] Ellos trabajan juntos. [end]                                             | [start] trabajan juntos [end]                                                 | Score(precision=1.0, recall=0.8, fmeasure=0.888888888888889)                                | Score(precision=0.6666666666666666, recall=0.5, fmeasure=0.5714285714285715)                  |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| I accept your challenge.                                                | [start] Acepto tu desafío. [end]                                                 | [start] acepto tu desafío [end]                                               | Score(precision=1.0, recall=1.0, fmeasure=1.0)                                              | Score(precision=1.0, recall=1.0, fmeasure=1.0)                                                |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| A wood floor is beautiful.                                              | [start] Un piso de madera es hermoso. [end]                                      | [start] la madera en el suelo es una hermosa [end]                            | Score(precision=0.4, recall=0.5, fmeasure=0.4444444444444445)                               | Score(precision=0.0, recall=0.0, fmeasure=0.0)                                                |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| AI means Artificial Intelligence.                                       | [start] IA quiere decir Inteligencia Artificial. [end]                           | [start] las mayor concierne a la inteligencia [end]                           | Score(precision=0.375, recall=0.42857142857142855, fmeasure=0.39999999999999997)            | Score(precision=0.0, recall=0.0, fmeasure=0.0)                                                |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| Onions cook more quickly than potatoes.                                 | [start] Las cebollas se cuecen más rápido que las papas. [end]                   | [start] las cebollas más de edad que el suficiente papas [end]                | Score(precision=0.6666666666666666, recall=0.6153846153846154, fmeasure=0.64)               | Score(precision=0.36363636363636365, recall=0.3333333333333333, fmeasure=0.34782608695652173) |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| What time will the game start?                                          | [start] ¿A qué hora empezará el juego? [end]                                     | [start] a qué hora arranca [end]                                              | Score(precision=0.8333333333333334, recall=0.625, fmeasure=0.7142857142857143)              | Score(precision=0.6, recall=0.42857142857142855, fmeasure=0.5)                                |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| He loves traveling.                                                     | [start] A él le encanta viajar. [end]                                            | [start] Él ama viajar [end]                                                   | Score(precision=0.8, recall=0.5714285714285714, fmeasure=0.6666666666666666)                | Score(precision=0.25, recall=0.16666666666666666, fmeasure=0.2)                               |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| I am good.                                                              | [start] Soy bueno. [end]                                                         | [start] soy bueno [end]                                                       | Score(precision=1.0, recall=1.0, fmeasure=1.0)                                              | Score(precision=1.0, recall=1.0, fmeasure=1.0)                                                |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| Let's stop wasting time.                                                | [start] Dejemos de perder tiempo. [end]                                          | [start] [UNK] de perder tiempo [end]                                          | Score(precision=0.8333333333333334, recall=0.8333333333333334, fmeasure=0.8333333333333334) | Score(precision=0.6, recall=0.6, fmeasure=0.6)                                                |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| My father will be forty soon.                                           | [start] Mi padre tendrá cuarenta pronto. [end]                                   | [start] mi padre va a los cuarenta años [end]                                 | Score(precision=0.5, recall=0.7142857142857143, fmeasure=0.588235294117647)                 | Score(precision=0.2222222222222222, recall=0.3333333333333333, fmeasure=0.26666666666666666)  |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| How many cars has that company bought?                                  | [start] ¿Cuántos autos compró esa compañía? [end]                                | [start] cuántos autos tiene esa compañía [end]                                | Score(precision=0.8888888888888888, recall=0.8888888888888888, fmeasure=0.8888888888888888) | Score(precision=0.75, recall=0.75, fmeasure=0.75)                                             |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| She used to wash her hair before going to school.                       | [start] Ella acostumbraba lavar su cabello antes de ir a la escuela. [end]       | [start] ella solía lavar el pelo antes de ir a la escuela [end]               | Score(precision=0.7142857142857143, recall=0.7692307692307693, fmeasure=0.7407407407407408) | Score(precision=0.5384615384615384, recall=0.5833333333333334, fmeasure=0.5599999999999999)   |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "| What were you two doing?                                                | [start] ¿Qué estabais haciendo vosotros dos? [end]                               | [start] qué estabas haciendo dos [end]                                        | Score(precision=0.8333333333333334, recall=0.7142857142857143, fmeasure=0.7692307692307692) | Score(precision=0.4, recall=0.3333333333333333, fmeasure=0.3636363636363636)                  |\n",
            "+-------------------------------------------------------------------------+----------------------------------------------------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "from rouge_score import rouge_scorer\n",
        "from tabulate import tabulate\n",
        "import keras_nlp\n",
        "\n",
        "rouge_1 = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
        "rouge_2 = rouge_scorer.RougeScorer(['rouge2'], use_stemmer=True)\n",
        "\n",
        "# Create a list to store results\n",
        "results = []\n",
        "\n",
        "for test_pair in test_pairs[:30]:\n",
        "    input_sentence = test_pair[0]\n",
        "    reference_sentence = test_pair[1]\n",
        "\n",
        "    translated_sentence = decode_sequence([input_sentence])\n",
        "    translated_sentence = (\n",
        "        translated_sentence.replace(\"[PAD]\", \"\")\n",
        "        .replace(\"[START]\", \"\")\n",
        "        .replace(\"[END]\", \"\")\n",
        "        .strip()\n",
        "    )\n",
        "\n",
        "    scores_1 = rouge_1.score(reference_sentence, translated_sentence)\n",
        "    scores_2 = rouge_2.score(reference_sentence, translated_sentence)\n",
        "\n",
        "    # Append results to the list\n",
        "    results.append([input_sentence, reference_sentence, translated_sentence,\n",
        "                    scores_1['rouge1'], scores_2['rouge2']])\n",
        "\n",
        "# Define headers for the table\n",
        "headers = [\"Input Sentence\", \"Reference Sentence\", \"Translated Sentence\", \"ROUGE-1 Score\", \"ROUGE-2 Score\"]\n",
        "\n",
        "# Print the table\n",
        "print(tabulate(results, headers=headers, tablefmt=\"grid\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Saving the transformer_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "mui_mW32LxpW"
      },
      "outputs": [],
      "source": [
        "model_save_path = 'transformer_model.h5'\n",
        "\n",
        "# Save the model to the specified file path\n",
        "transformer.save(model_save_path)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "neural_machine_translation_with_transformer",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
